/*********************************************************
Usecase 1 - R Script for Employee Attrition Training - TESTED OK
Author: Snehotosh Banerjee
Date: 07/03/2017

ORE Script Name:
	CLASSSVMCHURN
	
Packages:
	randomForest # RandomForest Algorithm
	caTools      # For Data Split
	ROCR	     # Visualizing classifier performance in R
	ggplot2      # Visualization
	DMwR	     # SMOTE for Rare class Balancing
	
Algorithm:
	Support Vector Machine 
	
Output Tables:
	AA_UC1_MDL_METRICS_TBL
	AA_UC1_MDL_IMG_TBL
	
*********************************************************/

BEGIN
sys.rqScriptDrop('CLASSSVMCHURN');
sys.rqScriptCreate('CLASSSVMCHURN',
                 'function(p_dataframe,perc_over,perc_under,kn,isR,p_spltratio,prim_class_label,pY,p_imputetype,ds.name){                 
                      #--------------------------------------------------------------------------
                      ## FORMULA for Model Building
                      #--------------------------------------------------------------------------                      
                      library(e1071)
                      
                      p_formula <- as.formula(paste(tail(names(p_dataframe), 1) , paste(head(names(p_dataframe), -1), collapse=" + "), sep=" ~ "))
                      
                      #--------------------------------------------------------------------------
                      ## PARAMETERS for Model Building
                      #--------------------------------------------------------------------------    
                      
                      p_topn = 20                                   
                      
                      #-------------------------------------------------------------------------
                      ## 0.Data splitting into train and validation Set
                      #-------------------------------------------------------------------------
                      data.split <- function(df,resVal,seedvalue,spltratio)
                      {
                        library(caTools)
                        set.seed(100)
                        split <- sample.split(Y = df[ ,resVal],SplitRatio = spltratio)				  
                      }            			
                      
                      #-------------------------------------------------------------------------
                      ## 1.Building SVM Model
                      #-------------------------------------------------------------------------
                    
                      mdl.training.SVM <- function(form,data){
                        # Tune
                        obj <- tune.svm(form, data = data,cost = 2^seq(-5,15,2),gamma = 2^seq(-15,3,2), kernel = "radial")
                        #obj <- tune.svm(form, data = data,cost = 2^seq(-5,1,2),gamma = 2^seq(-15,-9,2), kernel = "radial")
                        
                        # Finding Optimum value of Cost and Gamma
                        opti.gamma <- obj$best.parameters[[1]]
                        opti.cost <- obj$best.parameters[[2]]
                        
                        # Model
                        mdlSVM <- svm(formula = form,data = data,probability = T,cost = opti.cost,gamma = opti.gamma)
                        return(mdlSVM)
                      }
                      
                      #-------------------------------------------------------------------------
                      ## 3.Model Metrics Display
                      # What percent of your predictions were correct?- Accuracy                    
                      # What percent of the positive cases did you catch? - recall
                      # What percent of positive predictions were correct? - precision
                      #-------------------------------------------------------------------------
                      metricROCR <- function(model,testdata,pY,ds.name,p_class_label)
                      {
                        library(ROCR)
                        library(ggplot2)
                        
                        # Predict
                        predSVM <- predict(object = model,newdata = testdata,probability = T,decision.values = TRUE)
                        predSVMProb <- attr(predSVM, "probabilities")[,2]
                        
                        # Creating predicted probability and actual label predicted dataframe
                        pred.df <- data.frame(predicted=predSVMProb,actual=as.numeric(ifelse(testdata[,pY]==p_class_label,1,0)))
                        pred.df <- pred.df[order(pred.df$predicted, decreasing=TRUE), ]
                        
                        # Calculate ROCR Prediction
                        pred.rocr <- prediction(predictions = pred.df$predicted, labels = pred.df$actual)
                    
                        # Stats
                        roc.perf <- performance(pred.rocr, measure = "tpr", x.measure = "fpr")
                        tpr.perf <- performance(pred.rocr, measure = "tpr")
                        fpr.perf <- performance(pred.rocr, measure = "fpr")
                        fnr.perf <- performance(pred.rocr, measure = "fnr")
                        tnr.perf <- performance(pred.rocr, measure = "tnr")
                        recall.perf <- performance(pred.rocr, measure = "prec", x.measure = "rec")
                        sensspec.perf <- performance(pred.rocr, measure = "sens", x.measure = "spec")
                        lift.perf <- performance(pred.rocr, measure = "lift", x.measure = "rpp")
                        auc.perf <- performance(pred.rocr, measure = "auc")
                        accuracy.perf <- performance(pred.rocr, measure = "acc")
                        err.perf <- performance(pred.rocr, measure = "err")
                        calibration.perf <- performance(pred.rocr, measure = "cal")
                        pcmiss.perf <- performance(pred.rocr,"pcmiss","lift")
                        prbe.perf <- performance(pred.rocr, "prbe")
                        
                        ## Scores ##
                        
                        # AUC Score
                        auc_score <- auc.perf@y.values[[1]]
                        
                        # Precision/Recall breakeven Score
                        prbe.score <- prbe.perf@x.values[[1]]
                        
                        # Accuracy Rate Score
                        acc_rate <- max(accuracy.perf@y.values[[1]])
                        
                        # Accuracy Rate gt 50% Score
                        acc_roc_gt_50 <- accuracy.perf@y.values[[1]][max(accuracy.perf@x.values[[1]] > 0.5)]
                        
                        # Error Rate Score
                        error_rate <- min(err.perf@y.values[[1]])    
                        
                        # Draw ROC curve
                        plot(roc.perf, main="ROC with Convex Hull", colorize=TRUE,print.cutoffs.at = seq(0.1, 0.9, 0.1), lwd = 2)
                        ch = performance(pred.rocr , "rch")
                        plot(ch, add = TRUE, lty = 2)
                        
                        # Recall-Precision Plot
                        plot(recall.perf,colorize = T,print.cutoffs.at = seq(0.1, 0.9, 0.1), lwd = 2,main = "Recall-Precision Plot")
                        
                        # Sensitivity-Specificity Plot
                        plot(sensspec.perf,colorize = T,print.cutoffs.at = seq(0.1, 0.9, 0.1), lwd = 2,main = "Sensitivity vs Specificity")
                        
                        # Lift Plot
                        plot(lift.perf,colorize = T,print.cutoffs.at = seq(0.1, 0.9, 0.1), lwd = 2,main = "Lift Plot")
                        
                        # Accuracy - Boxplot (Spread)
                        plot(accuracy.perf, avg= "vertical", spread.estimate="boxplot", show.spread.at= seq(0.1, 1.0, by=0.1),main = "Accuracy - Boxplot (Spread)")
                        
                        # Accuracy vs Cutoff
                        # Get the cutoff for the best accuracy
                        bestAccInd <- which.max(accuracy.perf@"y.values"[[1]])
                        bestMsg <- paste("best accuracy=", accuracy.perf@"y.values"[[1]][bestAccInd],"at cutoff=", round(accuracy.perf@"x.values"[[1]][bestAccInd], 4))
                        plot(accuracy.perf, sub=bestMsg,main = "Accuracy vs Cutoff")
                        
                        # TPR vs Cutoff
                        plot(tpr.perf,main = "TPR vs Cutoff")
                        
                        # TNR vs Cutoff
                        plot(tnr.perf,main = "TNR vs Cutoff")
                        
                        # FPR vs Cutoff
                        plot(fpr.perf,main = "FPR vs Cutoff")
                        
                        # FNR vs Cutoff
                        plot(fnr.perf,main = "FNR vs Cutoff")
                        
                        # Prediction-conditioned miss 
                        plot(pcmiss.perf, colorize=T, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(1.2,1.2), avg="threshold", lwd=3)
                        
                        ## Various Metric Plots ##
                        # pos/neg densities
                        print(ggplot(data=pred.df,aes(x=predicted)) + geom_density(aes(fill=factor(actual)), size=1, alpha=.3) +
                                scale_x_continuous("Predicted", breaks=(0:4)/4, limits=c(0,1), labels=sprintf("%d%%", (0:4)*25)) +
                                scale_y_sqrt("Density") + scale_fill_manual(values = c("red","green")) + ggtitle(label = "Label Separation Density Curve"))
                        
                        # Confusion Matrix
                        confusionMatrix <- table(predSVM ,testdata[,pY])
                        confusionMatrix
                        
                        ore.save(confusionMatrix,name = ds.name,append = TRUE)
                        
                        # Basic measures calculation from CM
                        TP <- confusionMatrix[1,1]
                        TN <- confusionMatrix[2,2]
                        FN <- confusionMatrix[1,2]
                        FP <- confusionMatrix[2,1]
                        TOT <- sum(confusionMatrix)      
                        
                        # Measures
                        Accuracy <- round(as.numeric((TP + TN)/TOT),3)
                        ErrorRate <- 1 - Accuracy
                        FPR <- round(as.numeric(FP/(TN+FP)),3)
                        Recall <- round(as.numeric(TP/(TP+FN)),3)
                        Specificity <- round(as.numeric(TN/(TN + FP)),3)
                        Precision <- round(as.numeric(TP/(TP+FP)),3)
                        Fvalue <- round(as.numeric(2*Recall*Precision/(Recall + Precision)),3)
                        
                        df <- rbind(auc_score = auc_score,acc_rocr = acc_rate,accuracy = Accuracy,acc_rocr_gt50 = acc_roc_gt_50,error_rate_rocr = error_rate,error_rate = ErrorRate,fpr = FPR,recall = Recall,specificity = Specificity,precision = Precision,fval = Fvalue)
                        #colnames(df) <- "scores"
                        perf_metric <- data.frame(name=rownames(df),score=df,row.names = NULL)   
                        perf_metric
                      }                
                      
                      # -------------------------------------------------------------------------
                      ## 4.Model Decision Tree prediction
                      # -------------------------------------------------------------------------
                      mdl.pred.RF <- function(model,validationset,predtype="class")
                      {
                        # predicting on the validation Set
                        predtree <- predict(object = model,newdata = validationset,type = predtype)  
                        return(predtree)
                      }    
                      
                      # -------------------------------------------------------------------
                      ## 5.Data Imputation
                      #--------------------------------------------------------------------
                      
                      impute.data <- function(data,imputetype="mean")
                      {
                        ## This function imputes NA by mean or median values
                        if(imputetype == "mean"){
                          for (i in which(sapply(data, is.numeric))) {
                            data[is.na(data[, i]), i] <- mean(data[, i],  na.rm = TRUE)
                          }
                        } else if(imputetype == "median") {
                          for (i in which(sapply(data, is.numeric))) {
                            data[is.na(data[, i]), i] <- median(data[, i],  na.rm = TRUE)
                          }
                        } else if(imputetype == "knn"){
                          library(DMwR)      
                          data <- knnImputation(data = data)
                        }else{
                          stop("wrong imputation type.Only mean,median and knn is supported")
                        }
                        
                        return(data)
                      }	
                      
                      # -------------------------------------------------------------------
                      ## 6.Converting formula to vectors of string
                      #--------------------------------------------------------------------	
                      
                      x_variables <- function(form,Y)
                      {
                        aa <- gsub(pattern =" ",replacement="",x=paste0(format(form), collapse = ""))
                        bb <- gsub(pattern = "[+~]",replacement=",",x=aa)
                        cc <- unlist(strsplit(x = bb,split = "[,]"))
                        xcols <- cc[!cc %in% c(Y)]			  
                        return(xcols)
                      }
                      
                      # -------------------------------------------------------------------
                      ## 7.Rare Class Balancing
                      #--------------------------------------------------------------------	                      
                      imbalance_correction <- function(form,data,perc.over,perc.under,k,isRequired)
                      {
                        # Handling class Imbalance
                        library(DMwR)
                        
                        if(isRequired == "Y"){
                          data_bal <- SMOTE(form = form,data = data,perc.over = perc.over,k = k,perc.under = perc.under)
                          
                          
                          return(data_bal)
                        }
                        else{
                          return(data)
                        }
                      }
                      
                      ######################################################
                      ## THE MAIN FUNCTION ##
                      ## This is the Entry point
                      ######################################################                  	    
                      
                      # Pulling dataset into ORE transparency Layer
                      dataset <- ore.pull(p_dataframe)        
                      
                      ## Find which columns are factors
                      factor_cols <- names(dataset)[sapply(dataset,is.character)]            
                      
                      ## Converting training character columns to factor
                      dataset[, factor_cols] <- lapply(dataset[, factor_cols], as.factor) 
                      
                      # Releveling
                      #dataset[ ,pY] <- relevel(factor(dataset[ ,pY]),prim_class_label)       
                      dataset[ ,pY] <- relevel(dataset[ ,pY],prim_class_label)  
                      
                      ## Data splitting into training and validation set
                      splt <- data.split(df = dataset,resVal = pY,seedvalue = 1000,spltratio = p_spltratio)
                      
                      # Creation of training and validation set
                      training <- subset(x = dataset,splt == TRUE)
                      validation <- subset(x = dataset,splt == FALSE)
                      
                      # Handling class Imbalance
                      training_bal <- imbalance_correction(form = p_formula,data = training,perc.over = perc_over,perc.under = perc_under,k = kn,isRequired = isR)
                      #training_bal[,pY] <- as.factor(training_bal[,pY])
                      
                      unbal <- table(training[,pY])
                      bal <- table(training_bal[,pY])
                      
                      # Imputing the NA on main dataset
                      training_imputed <- impute.data(data = training_bal,imputetype = p_imputetype)
                      validation_imputed <- impute.data(data = validation,imputetype = p_imputetype)    
                      
                      print("#################################################")
                      print("***1.Model Building -  SVM ...")
                      print("#################################################")                      
                
                      ## Conversion of CHAR columns to FACTOR
                      # Training Data Predictors
                      training_imputed[sapply(training_imputed, is.character)] <- lapply(training_imputed[sapply(training_imputed, is.character)], as.factor)
                      
                      # Validation Data Predictors
                      validation_imputed[sapply(validation_imputed, is.character)] <- lapply(validation_imputed[sapply(validation_imputed, is.character)], as.factor)
                      
                      print("***2.Training the RF Model")
                      modSVM <- mdl.training.SVM(form = p_formula, data = training_imputed) 
                      
                      #print("***3.Random Forest Variable Importance")
                      #print(varImpPlot(modRF))
                      
                      #varImp <- modRF$importance
                      #varImp_MDG <- varImp[order(varImp[,2],decreasing = T),][,c(1,2)]
                      #varImp_MDA <- varImp[order(varImp[,3],decreasing = T),][,c(1,3)]
                      
                      print("#################################################")
                      print("***.COMPLETED - Model Building -  SVM...")
                      print("#################################################")
                      
                      if (nrow(ore.datastore(name=ds.name)) > 0 ) 
                      {
                        ore.delete(name = ds.name)
                      }
                      ore.save(modSVM,name = ds.name,append = TRUE)
                      #ore.save(varImp,name = ds.name,append= TRUE)
                      #ore.save(varImp_MDG,name = ds.name,append= TRUE)
                      #ore.save(varImp_MDA,name = ds.name,append= TRUE)
                      ore.save(unbal,name = ds.name,append= TRUE)
                      ore.save(bal,name = ds.name,append= TRUE)
                      
                      print("***3.Model Metrics...")
                      
                      summary(validation_imputed)
                      mdl_metric_SVM <- metricROCR(model = modSVM,testdata = validation_imputed,pY = pY,ds.name = ds.name,p_class_label=prim_class_label)
                      
                      # Returning the Metrics                   
                      mdl_metric_SVM
                 }');
end;
  

SELECT * FROM TABLE(rqTableEval(
                                cursor(select NATIONALITY , GENDER , AGE , MARITAL_STATUS , TENURE , CHNG_COMPA_L4Y , CHNG_COMPA_LY , 
                                      AVG_PERF_L4Y , CHNG_SICKLV_L4Y , CHNG_SICKLV_LY , DEPT_CHNG_L4Y , PROMO_L4Y , SALREV_L4Y , 
                                      SVR_CHNG_L4Y, ISCHURN FROM AA_COMMN_MDL_TRAIN_TBL),
                                cursor(select 1 as "ore.connect",300 "perc_over",200 "perc_under",20 "kn",
                                'Y' "isR",0.80 "p_spltratio",'Y' "prim_class_label",
                                'ISCHURN' "pY" ,'mean' "p_imputetype",'dsSVM_churn_store' "ds.name" from dual),
                                'select CAST(1 as VARCHAR2(20)) METRIC, 1 SCORE from dual',
                                'CLASSSVMCHURN'));

